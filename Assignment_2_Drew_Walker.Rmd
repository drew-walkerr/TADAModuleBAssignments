---
title: "Assignment_2_Drew_Walker"
author: "Drew Walker"
date: "11/30/2021"
output: html_document
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tm)
library(caTools)
library(rfUtilities)
library(e1071)
library(caTools)
library(mltest)
library(stringr)
library(randomForest)
library(caTools)
library(caret)
library(caretEnsemble)

```

```{r dataload}
annotated_dataset <- read.csv("TADA_Annotated_data.csv")
unlabeled_dataset <- read.csv("TADA_unlabeled_data.csv")

annotated_dataset <- annotated_dataset %>% 
  rename(CLASS = class)
annotated_text <- annotated_dataset$text


tweet_corpus <- VCorpus(VectorSource(annotated_text))

```

Due to errors in preprocessing, we had to remove emoji characters from the dataset. THis is a potential limitation of the study given the potential for emojis to be used to signify illicit use of substances. (Citation?)

# preprocessing
```{r preprocess}
myStopWords <- c(stopwords())
corpus <- tweet_corpus %>% 
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>% 
  tm_map(removeWords,myStopWords) %>% 
  tm_map(stemDocument)
length(corpus)
```

```{r ngrams-tokenizer}
NLP_tokenizer <- function(x){
  unlist(lapply(ngrams(words(x),1:3),paste,collapse = "_"),use.names=FALSE)
}
n_gram_corpus <- tm_map(corpus,content_transformer(NLP_tokenizer))
```

```{r, viewlength}
length(n_gram_corpus)
n_gram_corpus[[2]]$content
```


## Creating ttraining and test data for ML
```{r creating-training-and-test}

set.seed(1234)
split = sample.split(annotated_dataset$CLASS, SplitRatio = 0.8)
training_ngram_corpus = subset(n_gram_corpus, split==TRUE)

eval_n_gram_corpus = subset(n_gram_corpus,split==FALSE)

training_classes <- subset(annotated_dataset$CLASS,split==TRUE)
eval_classes <- subset(annotated_dataset$CLASS,split==FALSE)
```

# Vectorize
```{r create-dtm}
training_dtm <- DocumentTermMatrix(training_ngram_corpus)
training_dtm_sparse <- removeSparseTerms(training_dtm,0.995)
```

# restricting columns for test set
```{r, restricting}
eval_dtm_sparse <- DocumentTermMatrix(eval_n_gram_corpus,list(dictionary=colnames(training_dtm_sparse)))
```

```{r dataframes}
training_dtm_df <- as.data.frame(as.matrix(training_dtm_sparse))
eval_dtm_df <- as.data.frame(as.matrix(eval_dtm_sparse))
colnames(training_dtm_df) <- make.names(colnames(training_dtm_df))
colnames(eval_dtm_df) <- make.names(colnames(eval_dtm_df))


training_dtm_df$CLASS <- training_classes
training_dtm_df$CLASS <- as.factor(training_dtm_df$CLASS)
```

#SVM Model
```{r svm}
trained_model <- svm(CLASS ~.,data=training_dtm_df)
```


```{r svm-predictions}
svm_predictions <- predict(trained_model, newdata=eval_dtm_df)
```

# SVM Accuracy
```{r accuracy-svm, warning=FALSE}
mltest::ml_test(svm_predictions,eval_classes)
svm_accuracy <- mltest::ml_test(svm_predictions,eval_classes)

```

#Random Forest Model
```{r random_forest}
rf_trained_model <- randomForest::randomForest(CLASS ~.,data=training_dtm_df)
```

Random forest predictions
```{r random-forest-predictions}
random_forest_predictions <- predict(rf_trained_model, newdata=eval_dtm_df)
```

# RF Accuracy
```{r accuracy-svm, warning=FALSE}
mltest::ml_test(random_forest_predictions,eval_classes)
rf_accuracy <- mltest::ml_test(random_forest_predictions,eval_classes)

save.image("SVM_and_rf_models.Rdata")
```
# Naive Bayes Classification

```{r knn}
load("SVM_and_rf_models.Rdata")

knn_pred <- knn(train = training_dtm_df, cl=training_classes, test = eval_dtm_df,k=80)


confusionMatrix(cm)

```



# Ensemble Classification

With ensemble voting for more categories than binary, may need to add more rules that determine a winner given a tie or instance where each algorithm determines new label

https://github.com/kmutya/Ensemble-Learning-in-R

```{r ensemble}
#load("SVM_and_rf_models.Rdata")
## 0 - nonmedical use
## 1 - consumption (prescribed) 
## 2 - information/mention
## 3 unrelated 
#levels(training_dtm_df$class) = #c("nonmedical","consumption","information_mention","unrelated")
#
#
## Example of Stacking algorithms
## create submodels
#control <- trainControl(method="repeatedcv", number=10, repeats=3, #savePredictions=TRUE, classProbs=TRUE)
#algorithmList <- c('rf', 'rpart', 'glm', 'knn', 'svmRadial')
#set.seed(1234)
#models <- caretList(class~., data=training_dtm_df, trControl=control, #methodList=algorithmList)
#results <- resamples(models)
#summary(results)
#dotplot(results)
#
#
```

